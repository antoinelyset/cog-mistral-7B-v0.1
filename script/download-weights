#!/usr/bin/env python

import os
import sys
import torch
from tensorizer import TensorSerializer
from transformers import AutoModelForCausalLM, AutoTokenizer

# append project directory to path so predict.py can be imported
sys.path.append('.')

from predict import MODEL_NAME, MODEL_CACHE, TOKEN_CACHE, TENSORIZED_MODEL_PATH

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    cache_dir=TOKEN_CACHE
)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    cache_dir=MODEL_CACHE
)

serializer = TensorSerializer(TENSORIZED_MODEL_PATH)
serializer.write_module(model)
serializer.close()